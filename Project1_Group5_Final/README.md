# NYC 311 Complaint Analysis - GU4243 Project 1

**Course:** GU4243 Applied Data Science  
**Group:** 5  
**Authors:** Ketaki Dabade (kvd2112), Junye Chen (jc6636), Rui Lin (rl3445), Xiao Xiao (xx2492)  
**Date:** February 2026

---

## Project Overview

This project analyzes NYC 311 complaints from January-June 2024 by integrating data from **five distinct sources**:
1. NYC 311 Service Requests (~1.5M records)
2. Weather Data (Open-Meteo API, ~4,300 hourly observations)
3. US Census Demographics (~200 NYC ZIP codes)
4. Airbnb Listings (~100K listings)
5. NYC Events (web scraping + manual curation)

The analysis includes comprehensive data cleaning, exploratory data analysis (EDA), preprocessing, and feature engineering to create a modeling-ready daily-by-borough panel dataset.

---

## Repository Structure

```
Project1_Group5_Final/
├── README.md                          # This file
├── Project1_Report.ipynb             # Main Jupyter notebook (executable)
├── Project1_Report_executed.ipynb    # Pre-executed version with outputs
├── data/
│   ├── BoroughEvents.csv             # Original processed dataset (reference)
│   └── BoroughEvents_final.csv       # Final output (generated by notebook)
└── raw_data/                          # Raw data files (see instructions below)
    ├── nyc_311_raw_2024.csv
    ├── weather_raw_2024.csv
    ├── census_demographics_raw.csv
    ├── new_york_listings_2024.csv
    └── web_scraped_nyc_jan_jun_2024_expanded.csv
```

---

## Prerequisites

### Required Software
- **Python 3.11** (the notebook is configured for Python 3.11 kernel)
- **Jupyter Notebook** or **JupyterLab**

### Required Python Packages
```
pandas==3.0.0
numpy==1.26.4
matplotlib==3.10.8
seaborn==0.13.2
scipy==1.17.0
scikit-learn==1.8.0
requests==2.32.5
beautifulsoup4==4.14.3
```

---

## Setup Instructions

### Step 1: Verify Python 3.11 Installation

```bash
# Check Python 3.11 is installed
python3.11 --version
# Should output: Python 3.11.0 (or 3.11.x)
```

If Python 3.11 is not installed, download it from [python.org](https://www.python.org/downloads/).

### Step 2: Install Required Packages

```bash
# Install all required packages for Python 3.11
python3.11 -m pip install --upgrade \
    pandas==3.0.0 \
    numpy==1.26.4 \
    matplotlib==3.10.8 \
    seaborn==0.13.2 \
    scipy==1.17.0 \
    scikit-learn==1.8.0 \
    requests==2.32.5 \
    beautifulsoup4==4.14.3 \
    jupyter
```

**Note:** If you encounter permission errors, add `--user` flag:
```bash
python3.11 -m pip install --user --upgrade [packages...]
```

### Step 3: Set Up Raw Data Files

**IMPORTANT:** The notebook reads raw data from `~/Downloads/raw/`. You must place the raw CSV files there:

```bash
# Create the raw data directory
mkdir -p ~/Downloads/raw

# Copy the 5 raw data files to this location:
# - nyc_311_raw_2024.csv
# - weather_raw_2024.csv
# - census_demographics_raw.csv
# - new_york_listings_2024.csv
# - web_scraped_nyc_jan_jun_2024_expanded.csv
```

**Alternative:** If you want to use a different directory, edit **Cell 12** in the notebook and change the `RAW_DIR` variable:
```python
RAW_DIR = os.path.expanduser('~/Downloads/raw')  # Change this path
```

### Step 4: Verify Jupyter Kernel

Check which Python kernel Jupyter will use:

```bash
jupyter kernelspec list
```

You should see a `python3` kernel pointing to Python 3.11. If not, create one:

```bash
python3.11 -m ipykernel install --user --name=python3 --display-name "Python 3 (ipykernel)"
```

---

## How to Run the Notebook

### Option 1: Run in Jupyter Notebook (Recommended)

1. **Navigate to the project directory:**
   ```bash
   cd ~/Desktop/Project1_Group5_Final
   ```

2. **Launch Jupyter Notebook:**
   ```bash
   jupyter notebook
   ```

3. **Open `Project1_Report.ipynb` in the browser**

4. **Verify the kernel:**
   - In the notebook menu: **Kernel → Change Kernel → Python 3 (ipykernel)**
   - Or check the top-right corner shows "Python 3"

5. **Run all cells:**
   - Menu: **Cell → Run All**
   - Or use keyboard shortcut: **Shift + Enter** for each cell
   - Or click **Restart & Run All** from the Kernel menu

6. **Wait for execution:**
   - Cell 12 (data loading) takes ~30-60 seconds
   - Total runtime: ~3-5 minutes depending on your machine

### Option 2: Run in JupyterLab

```bash
cd ~/Desktop/Project1_Group5_Final
jupyter lab
```

Then follow the same steps as Option 1.

### Option 3: Run from Command Line (Non-Interactive)

To execute the notebook and generate a new output version:

```bash
cd ~/Desktop/Project1_Group5_Final
jupyter nbconvert --to notebook --execute --inplace Project1_Report.ipynb
```

Or to create a new executed copy:

```bash
jupyter nbconvert --to notebook --execute Project1_Report.ipynb --output Project1_Report_executed.ipynb
```

---

## Expected Output

### During Execution

The notebook will:
1. Load ~1.5M 311 complaint records from raw CSV
2. Process weather, census, Airbnb, and event data
3. Merge into a 910-row × 42-column daily-by-borough panel
4. Perform data cleaning (imputation, outlier handling)
5. Generate 13+ EDA visualizations
6. Engineer features (normalization, one-hot encoding, interactions, lags)
7. Save final dataset to `data/BoroughEvents_final.csv`

### Final Output Files

- **`data/BoroughEvents_final.csv`** - Processed dataset with all engineered features (~910 rows × 70+ columns)

### Visualizations

The notebook generates:
- Distribution plots (histograms + KDE)
- Time series plots (borough trends, moving averages)
- Boxplots and violin plots (borough comparisons)
- Scatter plots with regression lines (weather-complaint relationships)
- Temporal pattern analysis (weekday, monthly, seasonal)
- Correlation heatmap
- Statistical test visualizations (t-tests, ANOVA)
- Autocorrelation function (ACF) plot

---

## Troubleshooting

### Issue 1: "No module named 'requests'"

**Solution:** Install the missing package for Python 3.11:
```bash
python3.11 -m pip install requests beautifulsoup4
```

### Issue 2: "FileNotFoundError: nyc_311_raw_2024.csv"

**Solution:** Make sure raw data files are in `~/Downloads/raw/`:
```bash
ls ~/Downloads/raw/
# Should show all 5 CSV files
```

### Issue 3: Kernel keeps dying or notebook hangs

**Solution:** The 311 data is large (~1.5M rows). Ensure you have at least **4GB RAM** available. If still failing, reduce the data by sampling:
```python
# In Cell 12, after loading raw_311, add:
raw_311 = raw_311.sample(n=500000, random_state=42)  # Use 500K instead of 1.5M
```

### Issue 4: "ImportError: numpy.core.multiarray"

**Solution:** Reinstall numpy and pandas with matching versions:
```bash
python3.11 -m pip install --force-reinstall numpy==1.26.4 pandas==3.0.0
```

### Issue 5: Plots not displaying

**Solution:** If running in terminal/non-GUI mode, ensure matplotlib backend is set:
```python
import matplotlib
matplotlib.use('TkAgg')  # or 'Qt5Agg'
```

---

## Converting to PDF

To generate a PDF report for submission:

```bash
cd ~/Desktop/Project1_Group5_Final

# Option 1: Using nbconvert (requires LaTeX)
jupyter nbconvert --to pdf Project1_Report.ipynb

# Option 2: Via HTML intermediate (works without LaTeX)
jupyter nbconvert --to html Project1_Report.ipynb
# Then open the HTML file in browser and Print to PDF

# Option 3: Using executed version
jupyter nbconvert --to pdf Project1_Report_executed.ipynb
```

**Note:** PDF conversion requires `pandoc` and LaTeX. Install if needed:
```bash
brew install pandoc
brew install --cask mactex  # Large download (~4GB)
```

---

## Key Findings Summary

- **Brooklyn** generates the most 311 complaints in absolute terms
- **Weekdays** see 30-40% more complaints than weekends (p < 0.001)
- **HEAT/HOT WATER** is the #1 complaint type, reflecting NYC's aging infrastructure
- **Temperature** shows positive correlation with complaint volume
- **Weekly seasonality** confirmed via autocorrelation analysis (7-day lag peak)
- **Borough differences** are highly significant (ANOVA p < 0.001)

---

## Team Member Contributions

| Member | Contributions |
|--------|---------------|
| **Ketaki Dabade (kvd2112)** | Data acquisition (NYC 311 API, Census API), data cleaning pipeline, outlier detection, missing value imputation, feature engineering (normalization, encoding), report writing |
| **Junye Chen (jc6636)** | Weather API integration, Airbnb data processing, panel construction, statistical hypothesis testing, GitHub repository management |
| **Rui Lin (rl3445)** | Web scraping (NYC events), EDA visualizations (time series, borough comparisons, temporal patterns), autocorrelation analysis, correlation heatmap |
| **Xiao Xiao (xx2492)** | Census demographic processing, zip-to-borough mapping, feature engineering (interaction terms, polynomial features, derived ratios), summary of findings, challenges and recommendations |

---

## References

- **NYC Open Data** - NYC 311 Service Requests: https://opendata.cityofnewyork.us/
- **Open-Meteo API** - Historical Weather Data: https://open-meteo.com/
- **US Census Bureau API** - American Community Survey: https://www.census.gov/data/developers.html
- **Kaggle** - Airbnb Open Data: https://www.kaggle.com/datasets/arianazmoudeh/airbnbopendata
- **Wikipedia** - Boroughs of New York City: https://en.wikipedia.org/wiki/Boroughs_of_New_York_City

---

## Contact

For questions or issues, contact any team member via their UNI email:
- kvd2112@columbia.edu
- jc6636@columbia.edu
- rl3445@columbia.edu
- xx2492@columbia.edu
